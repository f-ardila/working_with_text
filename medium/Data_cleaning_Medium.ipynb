{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Archive  Analysis (Data Cleaning Phase)\n",
    "In this notebook I will clean the data pulled from medium's archive pages with the scrape_master.py file. I will focus on removing duplicate entries and analyzing potential concerns of data consistency.\n",
    "\n",
    "## Where the data came from.\n",
    "\n",
    "I pulled this data from Medium's archive pages. Each archive page is associated to a story-tag and is a collection of Medium timeline cards organized by date.\n",
    "\n",
    "#### Image of the \"data-science\" Archive\n",
    "\n",
    "<img src=\"img/archive.jpg\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### How the data was scraped\n",
    "The data was pulled from from  95 popular Medium story-tag archives. Each archive was <b>scraped for each day between Aug 1, 2017 and Aug 1, 2018.</b>\n",
    "\n",
    "These specific dates were chosen because:\n",
    "1. Medium's clap metric was introduced in August 2017, and older posts might not be relevant. \n",
    "2. The popularity of Medium may have grown, so older posts may not generalize to the preformance of posts today. \n",
    "3. The end date was chosen so that newer posts (September) were not included, as they have not had time to mature and accumulate claps.\n",
    "\n",
    "#### The 95 Tags Scraped\n",
    "['android', 'apple', 'architecture', 'art', 'bitcoin', 'blacklivesmatter', 'blockchain', 'blog', 'blogging', 'books', 'branding', 'business', 'college', 'creativity', 'cryptocurrency', 'culture', 'deep-learning', 'design', 'dogs', 'donald-trump', 'economics', 'education', 'energy', 'entrepreneurship', 'environment', 'ethereum', 'feminism', 'fiction', 'food', 'football', 'gadgets', 'google', 'government', 'happiness', 'health', 'history', 'humor', 'inspiration', 'interior-design', 'investing', 'ios', 'javascript', 'jobs', 'journalism', 'leadership', 'life', 'life-lessons', 'love', 'machine-learning', 'marketing', 'medium', 'mobile', 'motivation', 'movies', 'music', 'nba', 'news', 'nutrition', 'parenting', 'personal-development', 'photography', 'poem', 'poetry', 'politics', 'product-design', 'productivity', 'programming', 'psychology', 'python', 'python', 'racism', 'react', 'relationships', 'science', 'self-improvement', 'social-media', 'software-engineering', 'sports', 'startup', 'tech', 'technology', 'travel', 'trump', 'ux', 'venture-capital', 'visual-design', 'web-design', 'web-development', 'women', 'wordpress', 'work', 'writing']\n",
    "\n",
    "## Purpose of the Data\n",
    " 1. To <b>create a performance metric for Medium's authors</b>, so they can compare their work to the rest of Medium.\n",
    " 2. To <b>compare the performance of authors and publications</b> on Medium.\n",
    " 3. To <b>create a leaderboard</b> of the top performing authors and publications in each tag .\n",
    " \n",
    " 4. To <b>find the differences that distinguish well-received articles.</b>\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "## Structure of the data\n",
    "- Title\n",
    "- Subtitle \n",
    "- Image (yes/no)\n",
    "- Author\n",
    "- Publication\n",
    "- Year - Month - Day\n",
    "- Tag\n",
    "- Reading Time\n",
    "- Claps\n",
    "- Comment (yes/no)\n",
    "- Story Url\n",
    "- Author URL\n",
    "\n",
    "<img src=\"img/card.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e7d0f81b05d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmedium\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmedium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/w3ll/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/w3ll/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "tech_files = glob.glob(\"TAG_SCRAPES/*.csv\")\n",
    "\n",
    "frames =[]\n",
    "for file in tech_files:\n",
    "    #all of the seperate scrapes from different tags\n",
    "    df = pd.read_csv(file)\n",
    "    frames.append(df)\n",
    "medium = pd.concat(frames)\n",
    "medium.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles scraped:  2113020\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles scraped (before cleaning): \",medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Converting Strings to Floats\n",
    "\n",
    "Before we can work with the data we need to <b>convert the \"Claps\" column from string to float values</b>. Note that the Object datatype is non-numeric. There is also an issue with <b>Claps in the form of \"5.5K\", rather than \"5500\".</b>\n",
    "\n",
    "### Preview of DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           object\n",
       "Subtitle        object\n",
       "Image            int64\n",
       "Author          object\n",
       "Publication     object\n",
       "Year             int64\n",
       "Month            int64\n",
       "Day              int64\n",
       "Tag             object\n",
       "Reading_Time     int64\n",
       "Claps           object\n",
       "Comment          int64\n",
       "url             object\n",
       "Author_url      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting Clap Information to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clap dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "#Claps entries higher than 999 are written \"5.5K\"\n",
    "# here we remove the \"K\", convert the string to float, then multiply by 1000.\n",
    "numeric_claps = []\n",
    "for x in medium.Claps:\n",
    "    if \"K\" in x:\n",
    "        numeric_claps.append(float(x[:-1])*1000)\n",
    "    else:\n",
    "        numeric_claps.append(x)\n",
    "medium[\"Claps\"] = numeric_claps\n",
    "medium[\"Claps\"] = pd.to_numeric(medium[\"Claps\"])\n",
    "print(\"Clap dtype: \", medium.dtypes[\"Claps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Removing Comment Entries\n",
    "Comment entries have been encoded into the data with the Comment column. Since these entries are not articles, I remove them in the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries to be removed:  118963\n",
      "Percentage of remaining data:  5.63 %\n"
     ]
    }
   ],
   "source": [
    "no_comm = medium[medium.Comment==0]\n",
    "no_comm = no_comm.drop([\"Comment\"], axis=1)\n",
    "print(\"Number of Entries to be removed: \", medium.shape[0]-no_comm.shape[0])\n",
    "print(\"Percentage of remaining data: \" ,round(((medium.shape[0]-no_comm.shape[0])/medium.shape[0])*100,2), \"%\")\n",
    "medium = no_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up  Urls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hackernoon.com/@mrogati?source=tag_archive---------0---------------------\n",
      "https://medium.com/@hristoborisov?source=tag_archive---------1---------------------\n",
      "https://medium.com/@laurentemma?source=tag_archive---------2---------------------\n"
     ]
    }
   ],
   "source": [
    "#before\n",
    "for i in range(3):\n",
    "    print(medium.Author_url.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium.url = medium.url.str.split(\"?\", expand=True)\n",
    "medium.Author_url = medium.Author_url.str.split(\"?\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hackernoon.com/@mrogati\n",
      "https://medium.com/@hristoborisov\n",
      "https://medium.com/@laurentemma\n"
     ]
    }
   ],
   "source": [
    "#after\n",
    "for i in range(3):\n",
    "    print(medium.Author_url.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Checking for Non Entries in the Data\n",
    "\n",
    "\n",
    "### All NaNs in Each Column\n",
    "We only have missing values in Title, Subtitle, or Publication. <b>NaNs in publication column because not all articles are published. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs\n",
      "Title                67651\n",
      "Subtitle            647096\n",
      "Image                    0\n",
      "Author                6981\n",
      "Publication        1339095\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "Tag                      0\n",
      "Reading_Time             0\n",
      "Claps                    0\n",
      "url                      0\n",
      "Author_url            6975\n",
      "\n",
      "Total Entries:   1994057\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs\")\n",
    "for x in range(13):\n",
    "    print(\"%-15s %10d\" % (medium.columns.values[x], medium.iloc[:,x].isna().sum()))\n",
    "print()\n",
    "print(\"Total Entries:  \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN Authors\n",
    "Medium is doing something weird with adding existing articles from sites like pcmag.com. The cards on the archive timeline have neither author nor publication. Since there are only a coulple hundred entries withou an author, I choose to remove these from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium = medium[medium.Author.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN Title and Subtitle Entries\n",
    "Sometimes when scraping the archive page, Titles are in weird formats. The result, <b> some articles titles are scraped as subtitles</b>.\n",
    "\n",
    "Here is a breakdown of the NonEntries in Title/SubTitle Columns. I choose to keep these in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN Title Entries:  67518\n",
      "Entries with NaN Title but existing SubTitle:  36242\n",
      "Entries with neither title nor subtitle:  31276\n"
     ]
    }
   ],
   "source": [
    "#Total entries with no Title\n",
    "print(\"Total NaN Title Entries: \", medium[medium.Title.isnull()].shape[0])\n",
    "\n",
    "#Entries with no title but with a subtitle\n",
    "print(\"Entries with NaN Title but existing SubTitle: \",medium[(medium.Title.isnull() & medium.Subtitle.notnull())].shape[0])\n",
    "\n",
    "#Neither Possible explanations?\n",
    "print(\"Entries with neither title nor subtitle: \", medium[(medium.Title.isnull() & medium.Subtitle.isnull())].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs\n",
      "Title                67518\n",
      "Subtitle            644600\n",
      "Image                    0\n",
      "Author                   0\n",
      "Publication        1338404\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "Tag                      0\n",
      "Reading_Time             0\n",
      "Claps                    0\n",
      "url                      0\n",
      "Author_url               0\n",
      "\n",
      "Total Entries:   1987076\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs\")\n",
    "for x in range(13):\n",
    "    print(\"%-15s %10d\" % (medium.columns.values[x], medium.iloc[:,x].isna().sum()))\n",
    "print()\n",
    "print(\"Total Entries:  \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Removing Duplicate Articles (Multi-tagged)\n",
    "Medium allows an  author to include 5 tags for each story.\n",
    "\n",
    "When we scraped the archive page, we scraped each individual tag. <b>As a result, stories will appear multiple times in our data (with different tags)</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encode the tags \n",
    "medium = pd.get_dummies(medium, columns = [\"Tag\"])\n",
    "\n",
    "#multi_tags is all entries in the dataset that have duplicates (includes all duplicates)\n",
    "multi_tags = medium[medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "print(\"There are: \", multi_tags.shape[0], \"Duplicated entries.\")\n",
    "print(\"Unique posts with multiple tags: \", multi_tags.shape[0]- medium[medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"], keep=\"last\")].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining each multitagged article into ONE row\n",
    "\n",
    "#### 1. Combine the onehot encoded tags of each multiposted article into one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag_ai</th>\n",
       "      <th>Tag_android</th>\n",
       "      <th>Tag_apple</th>\n",
       "      <th>Tag_architecture</th>\n",
       "      <th>Tag_art</th>\n",
       "      <th>Tag_artificial-intelligence</th>\n",
       "      <th>Tag_big-data</th>\n",
       "      <th>Tag_bitcoin</th>\n",
       "      <th>Tag_blacklivesmatter</th>\n",
       "      <th>Tag_blockchain</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_travel</th>\n",
       "      <th>Tag_trump</th>\n",
       "      <th>Tag_ux</th>\n",
       "      <th>Tag_venture-capital</th>\n",
       "      <th>Tag_web-design</th>\n",
       "      <th>Tag_web-development</th>\n",
       "      <th>Tag_women</th>\n",
       "      <th>Tag_wordpress</th>\n",
       "      <th>Tag_work</th>\n",
       "      <th>Tag_writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tag_ai  Tag_android  Tag_apple  Tag_architecture  Tag_art  \\\n",
       "0       0            0          0                 0        1   \n",
       "1       0            0          0                 0        0   \n",
       "\n",
       "   Tag_artificial-intelligence  Tag_big-data  Tag_bitcoin  \\\n",
       "0                            0             0            0   \n",
       "1                            0             0            0   \n",
       "\n",
       "   Tag_blacklivesmatter  Tag_blockchain     ...       Tag_travel  Tag_trump  \\\n",
       "0                     0               0     ...                0          0   \n",
       "1                     0               0     ...                0          0   \n",
       "\n",
       "   Tag_ux  Tag_venture-capital  Tag_web-design  Tag_web-development  \\\n",
       "0       0                    0               0                    0   \n",
       "1       0                    0               0                    0   \n",
       "\n",
       "   Tag_women  Tag_wordpress  Tag_work  Tag_writing  \n",
       "0          0              0         0            0  \n",
       "1          0              0         0            0  \n",
       "\n",
       "[2 rows x 95 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groupby urls since a unique story has a unique url, sum the rows for all tags\n",
    "#now all tag vectors will be on one line\n",
    "gb = multi_tags.groupby([\"url\",\"Year\",\"Month\",\"Day\"]).sum().reset_index()\n",
    "tags = gb.iloc[:,7:].copy()\n",
    "tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2 Remove all but one of each duplicate entry, then sort, so rows match up with the groupby dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentrepreneuriat social : un moyen de sortir d...</td>\n",
       "      <td>Lengagement de Claudia, avec son organisation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATD Quart Monde Int</td>\n",
       "      <td>1001 Histoires</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://1001histoires.atd-quartmonde.org/lentr...</td>\n",
       "      <td>https://1001histoires.atd-quartmonde.org/@ATDQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Networking and Mentoring Done Right</td>\n",
       "      <td>How Cortado from Ten Thousand Coffees gives ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ten Thousand Coffees</td>\n",
       "      <td>Ten Thousand Coffees</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>https://10kcblog.com/cortadoworkplace-tenthous...</td>\n",
       "      <td>https://10kcblog.com/@10kcoffees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Lentrepreneuriat social : un moyen de sortir d...   \n",
       "1                Networking and Mentoring Done Right   \n",
       "\n",
       "                                            Subtitle  Image  \\\n",
       "0  Lengagement de Claudia, avec son organisation ...      0   \n",
       "1  How Cortado from Ten Thousand Coffees gives ev...      1   \n",
       "\n",
       "                 Author           Publication  Year  Month  Day  Reading_Time  \\\n",
       "0   ATD Quart Monde Int        1001 Histoires  2017      8   23             4   \n",
       "1  Ten Thousand Coffees  Ten Thousand Coffees  2018      5   25             3   \n",
       "\n",
       "   Claps                                                url  \\\n",
       "0    0.0  https://1001histoires.atd-quartmonde.org/lentr...   \n",
       "1   72.0  https://10kcblog.com/cortadoworkplace-tenthous...   \n",
       "\n",
       "                                          Author_url  \n",
       "0  https://1001histoires.atd-quartmonde.org/@ATDQ...  \n",
       "1                   https://10kcblog.com/@10kcoffees  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only one entry of each duplicated article\n",
    "sort = multi_tags[~multi_tags.duplicated(subset=[\"url\",\"Year\", \"Month\",\"Day\"], keep=\"first\")]\n",
    "\n",
    "#sort the entry to put it in the exact same order as the groupby above\n",
    "sort = sort.sort_values([\"url\",\"Year\",\"Month\",\"Day\"]).reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "#keep only the combined tags for a merge later\n",
    "sort = sort.iloc[:,:12].copy()\n",
    "sort.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Check that the two frames are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check the two dataframes match up\n",
    "(sort.url==gb.url).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Combine the two dataframes horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_travel</th>\n",
       "      <th>Tag_trump</th>\n",
       "      <th>Tag_ux</th>\n",
       "      <th>Tag_venture-capital</th>\n",
       "      <th>Tag_web-design</th>\n",
       "      <th>Tag_web-development</th>\n",
       "      <th>Tag_women</th>\n",
       "      <th>Tag_wordpress</th>\n",
       "      <th>Tag_work</th>\n",
       "      <th>Tag_writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentrepreneuriat social : un moyen de sortir d...</td>\n",
       "      <td>Lengagement de Claudia, avec son organisation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATD Quart Monde Int</td>\n",
       "      <td>1001 Histoires</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Networking and Mentoring Done Right</td>\n",
       "      <td>How Cortado from Ten Thousand Coffees gives ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ten Thousand Coffees</td>\n",
       "      <td>Ten Thousand Coffees</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Lentrepreneuriat social : un moyen de sortir d...   \n",
       "1                Networking and Mentoring Done Right   \n",
       "\n",
       "                                            Subtitle  Image  \\\n",
       "0  Lengagement de Claudia, avec son organisation ...      0   \n",
       "1  How Cortado from Ten Thousand Coffees gives ev...      1   \n",
       "\n",
       "                 Author           Publication  Year  Month  Day  Reading_Time  \\\n",
       "0   ATD Quart Monde Int        1001 Histoires  2017      8   23             4   \n",
       "1  Ten Thousand Coffees  Ten Thousand Coffees  2018      5   25             3   \n",
       "\n",
       "   Claps     ...      Tag_travel Tag_trump  Tag_ux  Tag_venture-capital  \\\n",
       "0    0.0     ...               0         0       0                    0   \n",
       "1   72.0     ...               0         0       0                    0   \n",
       "\n",
       "   Tag_web-design  Tag_web-development  Tag_women  Tag_wordpress  Tag_work  \\\n",
       "0               0                    0          0              0         0   \n",
       "1               0                    0          0              0         0   \n",
       "\n",
       "   Tag_writing  \n",
       "0            0  \n",
       "1            0  \n",
       "\n",
       "[2 rows x 107 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smoosh em\n",
    "combined = pd.concat([sort, tags], axis=1, sort=False)\n",
    "combined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Remove all duplicates from original dataframe, append combined entries to the bottom of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicate rows deleted:  596043\n"
     ]
    }
   ],
   "source": [
    "before = medium.shape[0]\n",
    "\n",
    "#Remove all duplicates articles with same date title and author\n",
    "medium = medium[~medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "#Add the combined data that we made in the last two scripts to the end of the datafream\n",
    "dframes = [medium, combined]\n",
    "#merge the two dataframes\n",
    "medium = pd.concat(dframes)\n",
    "\n",
    "after = medium.shape[0]\n",
    "print(\"# of duplicate rows deleted: \", before-after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "How much data do we have after cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of after cleaning:  1391033\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of after cleaning: \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium.to_csv(\"Medium_Clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
